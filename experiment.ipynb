{"nbformat":4,"nbformat_minor":5,"metadata":{"accelerator":"GPU","colab":{"name":"experiment.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.7"}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6mr3M2H7DFkQ","executionInfo":{"status":"ok","timestamp":1637477677977,"user_tz":-480,"elapsed":261,"user":{"displayName":"Yi-Jing Sie","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08533209739136415786"}},"outputId":"d7c5d24d-ba7f-4c10-c5bb-c25fce7e1fa9"},"source":["# please make sure that your GPU RAM is lager than 25GB \n","PATH = 'VRDL/VRDL_hw2' #you should key in the path of folder that contain this ipynb file\n","'''\n","for example, in my setting, I put this ipynb file folder in 'VRDL/VRDL_HW2' on My Drive\n","then PATH will be\n","'VRDL/VRDL_HW2'\n","'''\n","\n","from google.colab import drive\n","drive._mount('/content/drive/')\n","\n","!ls gdrive/MyDrive/\n","!nvidia-smi\n","\n","import os\n","os.chdir('./drive/MyDrive/')\n","\n","os.chdir(f'./{PATH}')\n"],"id":"6mr3M2H7DFkQ","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n","ls: cannot access 'gdrive/MyDrive/': No such file or directory\n","Sun Nov 21 06:54:36 2021       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 495.44       Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   36C    P0    27W / 250W |      0MiB / 16280MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":54},"id":"P_j6DF1vP1s1","executionInfo":{"status":"ok","timestamp":1637477712211,"user_tz":-480,"elapsed":274,"user":{"displayName":"Yi-Jing Sie","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08533209739136415786"}},"outputId":"02c41cc2-68a5-4e85-abb6-c93996d28725"},"source":["import torch\n","print(torch.__version__)\n","import numpy\n","numpy.version.version"],"id":"P_j6DF1vP1s1","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["1.10.0\n"]},{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'1.19.5'"]},"metadata":{},"execution_count":4}]},{"cell_type":"code","metadata":{"id":"MRglhfE2SmTr","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1637477667645,"user_tz":-480,"elapsed":300615,"user":{"displayName":"Yi-Jing Sie","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08533209739136415786"}},"outputId":"a9095363-3579-46d5-e5e6-18286b67983d"},"source":["# install some requirement\n","# please note that after reinstall the version of pytorch\n","# the kernel will restart because you update the version of pytorch.\n","# then you don't need to rerun this cell again!\n","!pip install -q condacolab\n","import condacolab\n","condacolab.install()\n","!conda install pytorch torchvision torchaudio cudatoolkit=10.2 -c pytorch"],"id":"MRglhfE2SmTr","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["‚è¨ Downloading https://github.com/jaimergp/miniforge/releases/latest/download/Mambaforge-colab-Linux-x86_64.sh...\n","üì¶ Installing...\n","üìå Adjusting configuration...\n","ü©π Patching environment...\n","‚è≤ Done in 0:00:24\n","üîÅ Restarting kernel...\n","Collecting package metadata (current_repodata.json): - \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\bdone\n","Solving environment: / \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| WARNING conda.core.solve:_add_specs(611): pinned spec cudatoolkit=11.1 conflicts with explicit specs.  Overriding pinned spec.\n","\b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\bdone\n","\n","## Package Plan ##\n","\n","  environment location: /usr/local\n","\n","  added / updated specs:\n","    - cudatoolkit=10.2\n","    - pytorch\n","    - torchaudio\n","    - torchvision\n","\n","\n","The following packages will be downloaded:\n","\n","    package                    |            build\n","    ---------------------------|-----------------\n","    _openmp_mutex-4.5          |           1_llvm           5 KB  conda-forge\n","    blas-2.106                 |              mkl          12 KB  conda-forge\n","    ca-certificates-2021.10.8  |       ha878542_0         139 KB  conda-forge\n","    certifi-2021.10.8          |   py37h89c1867_1         145 KB  conda-forge\n","    conda-4.10.3               |   py37h89c1867_4         3.0 MB  conda-forge\n","    cudatoolkit-10.2.89        |       h8f6ccaa_8       449.7 MB  conda-forge\n","    ffmpeg-4.3.2               |       hca11adc_0        92.0 MB  conda-forge\n","    freetype-2.10.4            |       h0708190_1         890 KB  conda-forge\n","    gmp-6.2.1                  |       h58526e2_0         806 KB  conda-forge\n","    gnutls-3.6.13              |       h85f3911_1         2.0 MB  conda-forge\n","    jpeg-9d                    |       h36c2ea0_0         264 KB  conda-forge\n","    lame-3.100                 |    h7f98852_1001         496 KB  conda-forge\n","    libblas-3.9.0              |            6_mkl          11 KB  conda-forge\n","    libcblas-3.9.0             |            6_mkl          11 KB  conda-forge\n","    libgfortran-ng-11.2.0      |      h69a702a_11          19 KB  conda-forge\n","    libgfortran5-11.2.0        |      h5c6108e_11         1.7 MB  conda-forge\n","    liblapack-3.9.0            |            6_mkl          11 KB  conda-forge\n","    liblapacke-3.9.0           |            6_mkl          11 KB  conda-forge\n","    libpng-1.6.37              |       h21135ba_2         306 KB  conda-forge\n","    libtiff-4.0.10             |    hc3755c2_1005         602 KB  conda-forge\n","    libuv-1.42.0               |       h7f98852_0         1.0 MB  conda-forge\n","    llvm-openmp-12.0.1         |       h4bd325d_1         2.8 MB  conda-forge\n","    mkl-2020.4                 |     h726a3e6_304       215.6 MB  conda-forge\n","    nettle-3.6                 |       he412f7d_0         6.5 MB  conda-forge\n","    numpy-1.20.3               |   py37h038b26d_1         5.7 MB  conda-forge\n","    olefile-0.46               |     pyh9f0ad1d_1          32 KB  conda-forge\n","    openh264-2.1.1             |       h780b84a_0         1.5 MB  conda-forge\n","    pillow-6.2.1               |   py37h6b7be26_0         637 KB  conda-forge\n","    python_abi-3.7             |          2_cp37m           4 KB  conda-forge\n","    pytorch-1.10.0             |py3.7_cuda10.2_cudnn7.6.5_0       768.3 MB  pytorch\n","    pytorch-mutex-1.0          |             cuda           3 KB  pytorch\n","    torchaudio-0.10.0          |       py37_cu102         4.5 MB  pytorch\n","    torchvision-0.11.1         |       py37_cu102        30.1 MB  pytorch\n","    typing_extensions-4.0.0    |     pyha770c72_0          26 KB  conda-forge\n","    x264-1!161.3030            |       h7f98852_1         2.5 MB  conda-forge\n","    ------------------------------------------------------------\n","                                           Total:        1.55 GB\n","\n","The following NEW packages will be INSTALLED:\n","\n","  blas               conda-forge/linux-64::blas-2.106-mkl\n","  cudatoolkit        conda-forge/linux-64::cudatoolkit-10.2.89-h8f6ccaa_8\n","  ffmpeg             conda-forge/linux-64::ffmpeg-4.3.2-hca11adc_0\n","  freetype           conda-forge/linux-64::freetype-2.10.4-h0708190_1\n","  gmp                conda-forge/linux-64::gmp-6.2.1-h58526e2_0\n","  gnutls             conda-forge/linux-64::gnutls-3.6.13-h85f3911_1\n","  jpeg               conda-forge/linux-64::jpeg-9d-h36c2ea0_0\n","  lame               conda-forge/linux-64::lame-3.100-h7f98852_1001\n","  libblas            conda-forge/linux-64::libblas-3.9.0-6_mkl\n","  libcblas           conda-forge/linux-64::libcblas-3.9.0-6_mkl\n","  libgfortran-ng     conda-forge/linux-64::libgfortran-ng-11.2.0-h69a702a_11\n","  libgfortran5       conda-forge/linux-64::libgfortran5-11.2.0-h5c6108e_11\n","  liblapack          conda-forge/linux-64::liblapack-3.9.0-6_mkl\n","  liblapacke         conda-forge/linux-64::liblapacke-3.9.0-6_mkl\n","  libpng             conda-forge/linux-64::libpng-1.6.37-h21135ba_2\n","  libtiff            conda-forge/linux-64::libtiff-4.0.10-hc3755c2_1005\n","  libuv              conda-forge/linux-64::libuv-1.42.0-h7f98852_0\n","  llvm-openmp        conda-forge/linux-64::llvm-openmp-12.0.1-h4bd325d_1\n","  mkl                conda-forge/linux-64::mkl-2020.4-h726a3e6_304\n","  nettle             conda-forge/linux-64::nettle-3.6-he412f7d_0\n","  numpy              conda-forge/linux-64::numpy-1.20.3-py37h038b26d_1\n","  olefile            conda-forge/noarch::olefile-0.46-pyh9f0ad1d_1\n","  openh264           conda-forge/linux-64::openh264-2.1.1-h780b84a_0\n","  pillow             conda-forge/linux-64::pillow-6.2.1-py37h6b7be26_0\n","  pytorch            pytorch/linux-64::pytorch-1.10.0-py3.7_cuda10.2_cudnn7.6.5_0\n","  pytorch-mutex      pytorch/noarch::pytorch-mutex-1.0-cuda\n","  torchaudio         pytorch/linux-64::torchaudio-0.10.0-py37_cu102\n","  torchvision        pytorch/linux-64::torchvision-0.11.1-py37_cu102\n","  typing_extensions  conda-forge/noarch::typing_extensions-4.0.0-pyha770c72_0\n","  x264               conda-forge/linux-64::x264-1!161.3030-h7f98852_1\n","\n","The following packages will be UPDATED:\n","\n","  ca-certificates                      2020.12.5-ha878542_0 --> 2021.10.8-ha878542_0\n","  certifi                          2020.12.5-py37h89c1867_1 --> 2021.10.8-py37h89c1867_1\n","  conda                                4.9.2-py37h89c1867_0 --> 4.10.3-py37h89c1867_4\n","  python_abi                                    3.7-1_cp37m --> 3.7-2_cp37m\n","\n","The following packages will be DOWNGRADED:\n","\n","  _openmp_mutex                                   4.5-1_gnu --> 4.5-1_llvm\n","\n","\n","\n","Downloading and Extracting Packages\n","freetype-2.10.4      | 890 KB    | : 100% 1.0/1 [00:00<00:00,  3.47it/s]\n","liblapacke-3.9.0     | 11 KB     | : 100% 1.0/1 [00:00<00:00,  6.07it/s]\n","ca-certificates-2021 | 139 KB    | : 100% 1.0/1 [00:00<00:00, 18.89it/s]\n","libgfortran5-11.2.0  | 1.7 MB    | : 100% 1.0/1 [00:00<00:00,  3.33it/s]\n","libpng-1.6.37        | 306 KB    | : 100% 1.0/1 [00:00<00:00, 11.49it/s]\n","torchvision-0.11.1   | 30.1 MB   | : 100% 1.0/1 [00:04<00:00,  4.32s/it]                \n","liblapack-3.9.0      | 11 KB     | : 100% 1.0/1 [00:00<00:00,  5.53it/s]\n","conda-4.10.3         | 3.0 MB    | : 100% 1.0/1 [00:00<00:00,  1.85it/s]\n","libblas-3.9.0        | 11 KB     | : 100% 1.0/1 [00:00<00:00,  5.27it/s]\n","olefile-0.46         | 32 KB     | : 100% 1.0/1 [00:00<00:00, 26.10it/s]\n","jpeg-9d              | 264 KB    | : 100% 1.0/1 [00:00<00:00, 12.70it/s]\n","ffmpeg-4.3.2         | 92.0 MB   | : 100% 1.0/1 [00:11<00:00, 11.37s/it]               \n","openh264-2.1.1       | 1.5 MB    | : 100% 1.0/1 [00:00<00:00,  3.85it/s]\n","typing_extensions-4. | 26 KB     | : 100% 1.0/1 [00:00<00:00, 26.71it/s]\n","libtiff-4.0.10       | 602 KB    | : 100% 1.0/1 [00:00<00:00,  6.77it/s]\n","_openmp_mutex-4.5    | 5 KB      | : 100% 1.0/1 [00:00<00:00, 29.39it/s]\n","cudatoolkit-10.2.89  | 449.7 MB  | : 100% 1.0/1 [01:04<00:00, 64.02s/it]               \n","blas-2.106           | 12 KB     | : 100% 1.0/1 [00:00<00:00,  4.37it/s]\n","libgfortran-ng-11.2. | 19 KB     | : 100% 1.0/1 [00:00<00:00, 25.56it/s]\n","torchaudio-0.10.0    | 4.5 MB    | : 100% 1.0/1 [00:01<00:00,  1.01s/it]\n","gnutls-3.6.13        | 2.0 MB    | : 100% 1.0/1 [00:00<00:00,  2.41it/s]\n","libcblas-3.9.0       | 11 KB     | : 100% 1.0/1 [00:00<00:00,  4.77it/s]\n","x264-1!161.3030      | 2.5 MB    | : 100% 1.0/1 [00:00<00:00,  2.46it/s]\n","lame-3.100           | 496 KB    | : 100% 1.0/1 [00:00<00:00,  8.49it/s]\n","pillow-6.2.1         | 637 KB    | : 100% 1.0/1 [00:00<00:00,  7.25it/s]\n","mkl-2020.4           | 215.6 MB  | : 100% 1.0/1 [00:35<00:00, 35.04s/it]               \n","llvm-openmp-12.0.1   | 2.8 MB    | : 100% 1.0/1 [00:00<00:00,  2.26it/s]\n","python_abi-3.7       | 4 KB      | : 100% 1.0/1 [00:00<00:00, 23.88it/s]\n","libuv-1.42.0         | 1.0 MB    | : 100% 1.0/1 [00:00<00:00,  5.59it/s]\n","nettle-3.6           | 6.5 MB    | : 100% 1.0/1 [00:00<00:00,  1.00it/s]\n","gmp-6.2.1            | 806 KB    | : 100% 1.0/1 [00:00<00:00,  6.26it/s]\n","pytorch-mutex-1.0    | 3 KB      | : 100% 1.0/1 [00:00<00:00,  3.80it/s]\n","pytorch-1.10.0       | 768.3 MB  | : 100% 1.0/1 [01:43<00:00, 103.56s/it]              \n","numpy-1.20.3         | 5.7 MB    | : 100% 1.0/1 [00:01<00:00,  1.08s/it]\n","certifi-2021.10.8    | 145 KB    | : 100% 1.0/1 [00:00<00:00, 18.72it/s]\n","Preparing transaction: / \b\b- \b\b\\ \b\bdone\n","Verifying transaction: / \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\bdone\n","Executing transaction: - \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- By downloading and using the CUDA Toolkit conda packages, you accept the terms and conditions of the CUDA End User License Agreement (EULA): https://docs.nvidia.com/cuda/eula/index.html\n","\n","\b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\bdone\n"]}]},{"cell_type":"code","metadata":{"id":"AWbAtg2PPuxL"},"source":[""],"id":"AWbAtg2PPuxL","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"K8v9Jlh7vlvm","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1637458600891,"user_tz":-480,"elapsed":282973,"user":{"displayName":"Yi-Jing Sie","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08533209739136415786"}},"outputId":"3382c1ae-8069-4bd3-e656-07e2124fc667"},"source":["%cd dataset\n","!unzip -q train.zip\n","!unzip -q test.zip\n","!mv train train\n","!mv test test\n","%cd .."],"id":"K8v9Jlh7vlvm","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/VRDL/VRDL_hw2/dataset\n","replace test/100000.png? [y]es, [n]o, [A]ll, [N]one, [r]ename: A\n","mv: cannot move 'test' to a subdirectory of itself, 'test/test'\n","/content/drive/My Drive/VRDL/VRDL_hw2\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3wqBBSzyybFB","executionInfo":{"status":"ok","timestamp":1637458966601,"user_tz":-480,"elapsed":270,"user":{"displayName":"Yi-Jing Sie","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08533209739136415786"}},"outputId":"6f1fbd74-78c6-4c5f-ae03-d01ae309bc8f"},"source":["#dataloader\n","import random as rd\n","import torch\n","import torch.utils.data as data\n","from torch.utils.data import Dataset, DataLoader\n","import py_files.utils as utils\n","from py_files.numloader import NumberDataset\n","\n","\n","rd.seed(0)\n","train_set = NumberDataset(is_train=True)\n","print(len(train_set))\n","ratio = 0.9\n","train_len = int(len(train_set)*ratio)\n","split_num = [train_len, len(train_set) - train_len]\n","train_set, val_set = data.random_split(train_set, split_num)\n","test_set = NumberDataset(is_train=False)\n","\n","\n"],"id":"3wqBBSzyybFB","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Testing set 13068\n"]}]},{"cell_type":"code","metadata":{"id":"ojxOasLrb2WR"},"source":["BATCH_SIZE = 2\n","train_loader = DataLoader(train_set, \n","                          batch_size = BATCH_SIZE,\n","                          shuffle = True,\n","                          pin_memory = True,\n","                          num_workers = 0,\n","                          collate_fn=utils.collate_fn)\n","\n","val_loader = DataLoader(val_set, \n","                          batch_size = BATCH_SIZE,\n","                          shuffle = False,\n","                          pin_memory = True,\n","                          num_workers = 0,\n","                          collate_fn=utils.collate_fn)\n","\n","test_loader = DataLoader(test_set, \n","                          batch_size = 1,\n","                          shuffle = False,\n","                          pin_memory = True,\n","                          collate_fn=utils.collate_fn)\n","\n"],"id":"ojxOasLrb2WR","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"PgFSUPi8Bwv4"},"source":["# https://www.uj5u.com/qita/27937.html\n","import torch\n","import torch.nn as nn\n","import torchvision\n","import torchvision.models as models\n","import py_files\n","from py_files import utils\n","from py_files import engine\n","from py_files.engine import train_one_epoch, evaluate\n","from tqdm import tqdm\n","import time\n","import json\n","from torchvision.models.detection.rpn import AnchorGenerator"],"id":"PgFSUPi8Bwv4","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"bDW1qrOi5FTS"},"source":["## 1. Retinanet with backbone resnet152"],"id":"bDW1qrOi5FTS"},{"cell_type":"code","metadata":{"id":"7D3N2y3P5D4l"},"source":[""],"id":"7D3N2y3P5D4l","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Clk8nHGZZxa2","outputId":"17be7b50-8aa0-489b-8905-9cde3d236e7f"},"source":["device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n","backbone = nn.Sequential(*list(models.resnet152(pretrained=True).children())[:-2]).to(device)\n","backbone.out_channels = 2048\n","anchor_generator = AnchorGenerator(\n","            sizes=((32, 64, 128, 256, 512),),\n","            aspect_ratios=((0.5, 1.0, 2.0),)\n",")\n","model = models.detection.RetinaNet(backbone,\n","                                    num_classes=10,\n","                                    anchor_generator=anchor_generator\n","                                    )\n","\n","model.to(device)\n","\n","# construct an optimizer\n","params = [p for p in model.parameters() if p.requires_grad]\n","\n","# SGD\n","optimizer = torch.optim.SGD(params, \n","                lr=0.0005,\n","                momentum=0.9, \n","                weight_decay=5e-4)\n","\n","# cos warmup annealing\n","lr_scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=1, T_mult=2)\n","\n","epochs = 31\n","\n","for epoch in range(0, epochs):\n","    # train for one epoch, printing every 10 iterations\n","    train_one_epoch(model, optimizer, train_loader, device, epoch, print_freq=1000)\n","    # save model parameter\n","    torch.save(model, f'./model_para/retinanet{epoch}.pt')\n","    # update the learning rate\n","    lr_scheduler.step()\n","    # evaluate on the test dataset    \n","    evaluate(model, val_loader, device=device)  \n","    print(\"=\"*60)  \n","print('finally finished.......QQQQQQ')\n"],"id":"Clk8nHGZZxa2","execution_count":null,"outputs":[{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/site-packages/torch/functional.py:445: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  /opt/conda/conda-bld/pytorch_1634272126608/work/aten/src/ATen/native/TensorShape.cpp:2157.)\n","  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: [0]  [    0/15031]  eta: 5:30:01  lr: 0.000001  loss: 0.4030 (0.4030)  classification: 0.1317 (0.1317)  bbox_regression: 0.2712 (0.2712)  time: 1.3173  data: 0.0299  max mem: 8727\n","Epoch: [0]  [ 1000/15031]  eta: 2:55:20  lr: 0.000500  loss: 0.3683 (0.4014)  classification: 0.1108 (0.1433)  bbox_regression: 0.2619 (0.2582)  time: 0.7694  data: 0.0045  max mem: 12610\n","Epoch: [0]  [ 2000/15031]  eta: 2:42:30  lr: 0.000500  loss: 0.4056 (0.3925)  classification: 0.1343 (0.1370)  bbox_regression: 0.2330 (0.2555)  time: 0.7356  data: 0.0041  max mem: 12611\n","Epoch: [0]  [ 3000/15031]  eta: 2:30:07  lr: 0.000500  loss: 0.3313 (0.3944)  classification: 0.0947 (0.1377)  bbox_regression: 0.2355 (0.2567)  time: 0.7506  data: 0.0042  max mem: 12612\n","Epoch: [0]  [ 4000/15031]  eta: 2:17:27  lr: 0.000500  loss: 0.3767 (0.3969)  classification: 0.1528 (0.1399)  bbox_regression: 0.2496 (0.2569)  time: 0.7434  data: 0.0045  max mem: 12612\n","Epoch: [0]  [ 5000/15031]  eta: 2:04:51  lr: 0.000500  loss: 0.3926 (0.3958)  classification: 0.1091 (0.1390)  bbox_regression: 0.2693 (0.2568)  time: 0.7373  data: 0.0044  max mem: 12612\n","Epoch: [0]  [ 6000/15031]  eta: 1:52:27  lr: 0.000500  loss: 0.4119 (0.3966)  classification: 0.1283 (0.1392)  bbox_regression: 0.2551 (0.2573)  time: 0.7401  data: 0.0042  max mem: 12612\n","Epoch: [0]  [ 7000/15031]  eta: 1:39:57  lr: 0.000500  loss: 0.3890 (0.3961)  classification: 0.1362 (0.1391)  bbox_regression: 0.2254 (0.2570)  time: 0.7444  data: 0.0042  max mem: 12930\n","Epoch: [0]  [ 8000/15031]  eta: 1:27:31  lr: 0.000500  loss: 0.3665 (0.3956)  classification: 0.1111 (0.1386)  bbox_regression: 0.2444 (0.2570)  time: 0.7651  data: 0.0038  max mem: 13498\n","Epoch: [0]  [ 9000/15031]  eta: 1:15:03  lr: 0.000500  loss: 0.3627 (0.3951)  classification: 0.0896 (0.1385)  bbox_regression: 0.2354 (0.2566)  time: 0.7752  data: 0.0041  max mem: 13498\n","Epoch: [0]  [10000/15031]  eta: 1:02:37  lr: 0.000500  loss: 0.3610 (0.3961)  classification: 0.1107 (0.1390)  bbox_regression: 0.2270 (0.2571)  time: 0.7369  data: 0.0042  max mem: 13498\n","Epoch: [0]  [11000/15031]  eta: 0:50:10  lr: 0.000500  loss: 0.3521 (0.3968)  classification: 0.1006 (0.1395)  bbox_regression: 0.2379 (0.2573)  time: 0.7377  data: 0.0038  max mem: 13498\n","Epoch: [0]  [12000/15031]  eta: 0:37:43  lr: 0.000500  loss: 0.3170 (0.3965)  classification: 0.0890 (0.1392)  bbox_regression: 0.2332 (0.2572)  time: 0.7462  data: 0.0042  max mem: 13498\n","Epoch: [0]  [13000/15031]  eta: 0:25:16  lr: 0.000500  loss: 0.3384 (0.3974)  classification: 0.0871 (0.1397)  bbox_regression: 0.2563 (0.2577)  time: 0.7364  data: 0.0045  max mem: 13498\n","Epoch: [0]  [14000/15031]  eta: 0:12:49  lr: 0.000500  loss: 0.3961 (0.3978)  classification: 0.1105 (0.1401)  bbox_regression: 0.2809 (0.2576)  time: 0.7575  data: 0.0037  max mem: 13498\n","Epoch: [0]  [15000/15031]  eta: 0:00:23  lr: 0.000500  loss: 0.3695 (0.3975)  classification: 0.1231 (0.1399)  bbox_regression: 0.2356 (0.2576)  time: 0.7350  data: 0.0039  max mem: 13498\n","Epoch: [0]  [15030/15031]  eta: 0:00:00  lr: 0.000500  loss: 0.3556 (0.3975)  classification: 0.1156 (0.1399)  bbox_regression: 0.2322 (0.2576)  time: 0.7306  data: 0.0040  max mem: 13498\n","Epoch: [0] Total time: 3:06:57 (0.7463 s / it)\n","============================================================\n","Epoch: [1]  [    0/15031]  eta: 2:52:40  lr: 0.000500  loss: 0.4402 (0.4402)  classification: 0.1339 (0.1339)  bbox_regression: 0.3063 (0.3063)  time: 0.6893  data: 0.0054  max mem: 13498\n","Epoch: [1]  [ 1000/15031]  eta: 2:53:45  lr: 0.000500  loss: 0.3545 (0.3733)  classification: 0.0985 (0.1263)  bbox_regression: 0.2241 (0.2470)  time: 0.7261  data: 0.0035  max mem: 13498\n","Epoch: [1]  [ 2000/15031]  eta: 2:41:59  lr: 0.000500  loss: 0.3747 (0.3782)  classification: 0.1243 (0.1283)  bbox_regression: 0.2346 (0.2499)  time: 0.7496  data: 0.0040  max mem: 13498\n","Epoch: [1]  [ 3000/15031]  eta: 2:29:24  lr: 0.000500  loss: 0.3862 (0.3805)  classification: 0.1118 (0.1287)  bbox_regression: 0.2537 (0.2518)  time: 0.7440  data: 0.0044  max mem: 13498\n","Epoch: [1]  [ 4000/15031]  eta: 2:16:51  lr: 0.000500  loss: 0.3689 (0.3798)  classification: 0.1094 (0.1294)  bbox_regression: 0.2449 (0.2504)  time: 0.7560  data: 0.0039  max mem: 13498\n","Epoch: [1]  [ 5000/15031]  eta: 2:04:33  lr: 0.000500  loss: 0.3474 (0.3810)  classification: 0.1137 (0.1297)  bbox_regression: 0.2266 (0.2514)  time: 0.7515  data: 0.0043  max mem: 13498\n","Epoch: [1]  [ 6000/15031]  eta: 1:52:08  lr: 0.000500  loss: 0.3883 (0.3815)  classification: 0.1179 (0.1296)  bbox_regression: 0.2704 (0.2519)  time: 0.7479  data: 0.0037  max mem: 13498\n","Epoch: [1]  [ 7000/15031]  eta: 1:39:44  lr: 0.000500  loss: 0.3524 (0.3820)  classification: 0.1219 (0.1302)  bbox_regression: 0.2179 (0.2518)  time: 0.7372  data: 0.0039  max mem: 13498\n","Epoch: [1]  [ 8000/15031]  eta: 1:27:18  lr: 0.000500  loss: 0.3132 (0.3824)  classification: 0.0781 (0.1304)  bbox_regression: 0.2253 (0.2519)  time: 0.7284  data: 0.0041  max mem: 13498\n","Epoch: [1]  [ 9000/15031]  eta: 1:14:55  lr: 0.000500  loss: 0.3929 (0.3826)  classification: 0.0966 (0.1303)  bbox_regression: 0.2550 (0.2523)  time: 0.7532  data: 0.0039  max mem: 13498\n","Epoch: [1]  [10000/15031]  eta: 1:02:29  lr: 0.000500  loss: 0.3572 (0.3831)  classification: 0.1259 (0.1305)  bbox_regression: 0.2298 (0.2526)  time: 0.7569  data: 0.0041  max mem: 13498\n","Epoch: [1]  [11000/15031]  eta: 0:50:07  lr: 0.000500  loss: 0.3487 (0.3845)  classification: 0.1110 (0.1311)  bbox_regression: 0.2291 (0.2534)  time: 0.7389  data: 0.0039  max mem: 13498\n","Epoch: [1]  [12000/15031]  eta: 0:37:41  lr: 0.000500  loss: 0.3527 (0.3856)  classification: 0.1090 (0.1317)  bbox_regression: 0.2552 (0.2539)  time: 0.7505  data: 0.0042  max mem: 13498\n","Epoch: [1]  [13000/15031]  eta: 0:25:15  lr: 0.000500  loss: 0.4517 (0.3861)  classification: 0.1341 (0.1320)  bbox_regression: 0.2910 (0.2541)  time: 0.7313  data: 0.0040  max mem: 13498\n","Epoch: [1]  [14000/15031]  eta: 0:12:49  lr: 0.000500  loss: 0.3256 (0.3863)  classification: 0.0900 (0.1324)  bbox_regression: 0.2127 (0.2539)  time: 0.7585  data: 0.0045  max mem: 13498\n","Epoch: [1]  [15000/15031]  eta: 0:00:23  lr: 0.000500  loss: 0.3215 (0.3864)  classification: 0.0998 (0.1326)  bbox_regression: 0.2435 (0.2538)  time: 0.7639  data: 0.0038  max mem: 13498\n","Epoch: [1]  [15030/15031]  eta: 0:00:00  lr: 0.000500  loss: 0.4509 (0.3865)  classification: 0.1219 (0.1327)  bbox_regression: 0.2763 (0.2538)  time: 0.7270  data: 0.0041  max mem: 13498\n","Epoch: [1] Total time: 3:06:52 (0.7460 s / it)\n","============================================================\n","Epoch: [2]  [    0/15031]  eta: 3:02:46  lr: 0.000250  loss: 0.5561 (0.5561)  classification: 0.1301 (0.1301)  bbox_regression: 0.4260 (0.4260)  time: 0.7296  data: 0.0059  max mem: 13498\n","Epoch: [2]  [ 1000/15031]  eta: 2:55:06  lr: 0.000250  loss: 0.3696 (0.3586)  classification: 0.0891 (0.1160)  bbox_regression: 0.2247 (0.2426)  time: 0.7534  data: 0.0040  max mem: 13498\n","Epoch: [2]  [ 2000/15031]  eta: 2:42:36  lr: 0.000250  loss: 0.3333 (0.3579)  classification: 0.0850 (0.1157)  bbox_regression: 0.2323 (0.2422)  time: 0.7743  data: 0.0045  max mem: 13498\n","Epoch: [2]  [ 3000/15031]  eta: 2:29:54  lr: 0.000250  loss: 0.3060 (0.3605)  classification: 0.0952 (0.1173)  bbox_regression: 0.1972 (0.2433)  time: 0.7711  data: 0.0043  max mem: 13498\n","Epoch: [2]  [ 4000/15031]  eta: 2:17:20  lr: 0.000250  loss: 0.3444 (0.3614)  classification: 0.0885 (0.1179)  bbox_regression: 0.2439 (0.2434)  time: 0.7716  data: 0.0039  max mem: 13498\n","Epoch: [2]  [ 5000/15031]  eta: 2:04:55  lr: 0.000250  loss: 0.3028 (0.3598)  classification: 0.0835 (0.1168)  bbox_regression: 0.1879 (0.2430)  time: 0.7704  data: 0.0043  max mem: 13498\n","Epoch: [2]  [ 6000/15031]  eta: 1:52:26  lr: 0.000250  loss: 0.3231 (0.3587)  classification: 0.0753 (0.1166)  bbox_regression: 0.2373 (0.2421)  time: 0.7390  data: 0.0041  max mem: 13498\n","Epoch: [2]  [ 7000/15031]  eta: 1:39:58  lr: 0.000250  loss: 0.3099 (0.3588)  classification: 0.0792 (0.1171)  bbox_regression: 0.2103 (0.2417)  time: 0.7436  data: 0.0040  max mem: 13498\n","Epoch: [2]  [ 8000/15031]  eta: 1:27:31  lr: 0.000250  loss: 0.3449 (0.3588)  classification: 0.0853 (0.1169)  bbox_regression: 0.2532 (0.2419)  time: 0.7624  data: 0.0047  max mem: 13498\n","Epoch: [2]  [ 9000/15031]  eta: 1:15:02  lr: 0.000250  loss: 0.3494 (0.3589)  classification: 0.0929 (0.1169)  bbox_regression: 0.2554 (0.2420)  time: 0.7709  data: 0.0038  max mem: 13498\n","Epoch: [2]  [10000/15031]  eta: 1:02:35  lr: 0.000250  loss: 0.4401 (0.3598)  classification: 0.1279 (0.1173)  bbox_regression: 0.2722 (0.2425)  time: 0.7224  data: 0.0042  max mem: 13498\n","Epoch: [2]  [11000/15031]  eta: 0:50:08  lr: 0.000250  loss: 0.3538 (0.3597)  classification: 0.0971 (0.1172)  bbox_regression: 0.2219 (0.2426)  time: 0.7493  data: 0.0038  max mem: 13498\n","Epoch: [2]  [12000/15031]  eta: 0:37:41  lr: 0.000250  loss: 0.3082 (0.3602)  classification: 0.1015 (0.1174)  bbox_regression: 0.1968 (0.2428)  time: 0.7372  data: 0.0039  max mem: 13498\n","Epoch: [2]  [13000/15031]  eta: 0:25:15  lr: 0.000250  loss: 0.3943 (0.3605)  classification: 0.1230 (0.1174)  bbox_regression: 0.2632 (0.2431)  time: 0.7323  data: 0.0040  max mem: 13498\n","Epoch: [2]  [14000/15031]  eta: 0:12:49  lr: 0.000250  loss: 0.3760 (0.3605)  classification: 0.1057 (0.1174)  bbox_regression: 0.2371 (0.2431)  time: 0.7260  data: 0.0042  max mem: 13498\n","Epoch: [2]  [15000/15031]  eta: 0:00:23  lr: 0.000250  loss: 0.2672 (0.3610)  classification: 0.0856 (0.1177)  bbox_regression: 0.1814 (0.2433)  time: 0.7526  data: 0.0047  max mem: 13498\n","Epoch: [2]  [15030/15031]  eta: 0:00:00  lr: 0.000250  loss: 0.3738 (0.3611)  classification: 0.1104 (0.1178)  bbox_regression: 0.2413 (0.2433)  time: 0.7159  data: 0.0042  max mem: 13498\n","Epoch: [2] Total time: 3:06:55 (0.7462 s / it)\n","============================================================\n","Epoch: [3]  [    0/15031]  eta: 3:14:00  lr: 0.000500  loss: 0.2597 (0.2597)  classification: 0.0738 (0.0738)  bbox_regression: 0.1859 (0.1859)  time: 0.7744  data: 0.0058  max mem: 13498\n","Epoch: [3]  [ 1000/15031]  eta: 2:54:32  lr: 0.000500  loss: 0.3186 (0.3566)  classification: 0.0937 (0.1164)  bbox_regression: 0.2304 (0.2402)  time: 0.7379  data: 0.0045  max mem: 13498\n","Epoch: [3]  [ 2000/15031]  eta: 2:42:04  lr: 0.000500  loss: 0.3433 (0.3578)  classification: 0.1113 (0.1175)  bbox_regression: 0.2457 (0.2403)  time: 0.7422  data: 0.0042  max mem: 13498\n","Epoch: [3]  [ 3000/15031]  eta: 2:29:48  lr: 0.000500  loss: 0.2981 (0.3604)  classification: 0.0797 (0.1181)  bbox_regression: 0.2214 (0.2423)  time: 0.7436  data: 0.0040  max mem: 13498\n","Epoch: [3]  [ 4000/15031]  eta: 2:17:08  lr: 0.000500  loss: 0.3863 (0.3638)  classification: 0.1091 (0.1203)  bbox_regression: 0.2316 (0.2435)  time: 0.7579  data: 0.0041  max mem: 13498\n","Epoch: [3]  [ 5000/15031]  eta: 2:04:41  lr: 0.000500  loss: 0.3414 (0.3656)  classification: 0.0886 (0.1209)  bbox_regression: 0.2542 (0.2446)  time: 0.7515  data: 0.0045  max mem: 13498\n","Epoch: [3]  [ 6000/15031]  eta: 1:52:16  lr: 0.000500  loss: 0.4458 (0.3673)  classification: 0.1251 (0.1218)  bbox_regression: 0.2924 (0.2455)  time: 0.7382  data: 0.0044  max mem: 13498\n","Epoch: [3]  [ 7000/15031]  eta: 1:39:52  lr: 0.000500  loss: 0.3522 (0.3681)  classification: 0.0887 (0.1223)  bbox_regression: 0.2442 (0.2458)  time: 0.7476  data: 0.0045  max mem: 13498\n","Epoch: [3]  [ 8000/15031]  eta: 1:27:28  lr: 0.000500  loss: 0.3771 (0.3689)  classification: 0.1288 (0.1227)  bbox_regression: 0.2401 (0.2462)  time: 0.7453  data: 0.0037  max mem: 13498\n","Epoch: [3]  [ 9000/15031]  eta: 1:15:03  lr: 0.000500  loss: 0.3443 (0.3694)  classification: 0.0736 (0.1231)  bbox_regression: 0.2478 (0.2463)  time: 0.7647  data: 0.0044  max mem: 13498\n","Epoch: [3]  [10000/15031]  eta: 1:02:38  lr: 0.000500  loss: 0.3442 (0.3706)  classification: 0.1275 (0.1236)  bbox_regression: 0.2183 (0.2470)  time: 0.7690  data: 0.0041  max mem: 13498\n","Epoch: [3]  [11000/15031]  eta: 0:50:10  lr: 0.000500  loss: 0.3664 (0.3713)  classification: 0.1303 (0.1242)  bbox_regression: 0.2513 (0.2471)  time: 0.7520  data: 0.0039  max mem: 13498\n","Epoch: [3]  [12000/15031]  eta: 0:37:42  lr: 0.000500  loss: 0.3432 (0.3723)  classification: 0.0858 (0.1245)  bbox_regression: 0.2500 (0.2479)  time: 0.7086  data: 0.0044  max mem: 13498\n","Epoch: [3]  [13000/15031]  eta: 0:25:16  lr: 0.000500  loss: 0.3643 (0.3725)  classification: 0.1051 (0.1245)  bbox_regression: 0.2303 (0.2481)  time: 0.7376  data: 0.0038  max mem: 13498\n","Epoch: [3]  [14000/15031]  eta: 0:12:49  lr: 0.000500  loss: 0.3895 (0.3734)  classification: 0.1267 (0.1249)  bbox_regression: 0.2637 (0.2485)  time: 0.7656  data: 0.0045  max mem: 13498\n","Epoch: [3]  [15000/15031]  eta: 0:00:23  lr: 0.000500  loss: 0.3583 (0.3738)  classification: 0.0898 (0.1250)  bbox_regression: 0.2461 (0.2488)  time: 0.7473  data: 0.0045  max mem: 13498\n","Epoch: [3]  [15030/15031]  eta: 0:00:00  lr: 0.000500  loss: 0.3327 (0.3738)  classification: 0.1091 (0.1251)  bbox_regression: 0.2326 (0.2488)  time: 0.7351  data: 0.0043  max mem: 13498\n","Epoch: [3] Total time: 3:07:02 (0.7466 s / it)\n","============================================================\n","Epoch: [4]  [    0/15031]  eta: 3:00:00  lr: 0.000427  loss: 0.4156 (0.4156)  classification: 0.0950 (0.0950)  bbox_regression: 0.3206 (0.3206)  time: 0.7185  data: 0.0084  max mem: 13498\n","Epoch: [4]  [ 1000/15031]  eta: 2:54:05  lr: 0.000427  loss: 0.3144 (0.3619)  classification: 0.0759 (0.1164)  bbox_regression: 0.2345 (0.2455)  time: 0.7410  data: 0.0047  max mem: 13498\n","Epoch: [4]  [ 2000/15031]  eta: 2:41:49  lr: 0.000427  loss: 0.3183 (0.3623)  classification: 0.1096 (0.1177)  bbox_regression: 0.2076 (0.2446)  time: 0.7336  data: 0.0042  max mem: 13498\n","Epoch: [4]  [ 3000/15031]  eta: 2:29:28  lr: 0.000427  loss: 0.3286 (0.3607)  classification: 0.0903 (0.1170)  bbox_regression: 0.2482 (0.2437)  time: 0.7621  data: 0.0041  max mem: 13498\n","Epoch: [4]  [ 4000/15031]  eta: 2:16:58  lr: 0.000427  loss: 0.3395 (0.3615)  classification: 0.0936 (0.1177)  bbox_regression: 0.2416 (0.2438)  time: 0.7319  data: 0.0041  max mem: 13498\n","Epoch: [4]  [ 5000/15031]  eta: 2:04:30  lr: 0.000427  loss: 0.3139 (0.3618)  classification: 0.0823 (0.1181)  bbox_regression: 0.2129 (0.2437)  time: 0.7443  data: 0.0039  max mem: 13498\n","Epoch: [4]  [ 6000/15031]  eta: 1:52:12  lr: 0.000427  loss: 0.3482 (0.3618)  classification: 0.0919 (0.1183)  bbox_regression: 0.2454 (0.2435)  time: 0.7620  data: 0.0040  max mem: 13498\n","Epoch: [4]  [ 7000/15031]  eta: 1:39:52  lr: 0.000427  loss: 0.4024 (0.3621)  classification: 0.0982 (0.1185)  bbox_regression: 0.2576 (0.2436)  time: 0.7370  data: 0.0038  max mem: 13498\n","Epoch: [4]  [ 8000/15031]  eta: 1:27:26  lr: 0.000427  loss: 0.3174 (0.3612)  classification: 0.0843 (0.1181)  bbox_regression: 0.2271 (0.2431)  time: 0.7651  data: 0.0040  max mem: 13498\n","Epoch: [4]  [ 9000/15031]  eta: 1:15:00  lr: 0.000427  loss: 0.3085 (0.3613)  classification: 0.0680 (0.1182)  bbox_regression: 0.2382 (0.2430)  time: 0.7305  data: 0.0042  max mem: 13498\n","Epoch: [4]  [10000/15031]  eta: 1:02:37  lr: 0.000427  loss: 0.3016 (0.3619)  classification: 0.0819 (0.1185)  bbox_regression: 0.2170 (0.2434)  time: 0.7430  data: 0.0043  max mem: 13498\n","Epoch: [4]  [11000/15031]  eta: 0:50:09  lr: 0.000427  loss: 0.3452 (0.3620)  classification: 0.1058 (0.1185)  bbox_regression: 0.2254 (0.2435)  time: 0.7471  data: 0.0044  max mem: 13498\n","Epoch: [4]  [12000/15031]  eta: 0:37:43  lr: 0.000427  loss: 0.2970 (0.3624)  classification: 0.0760 (0.1187)  bbox_regression: 0.2217 (0.2436)  time: 0.7703  data: 0.0040  max mem: 13498\n","Epoch: [4]  [13000/15031]  eta: 0:25:16  lr: 0.000427  loss: 0.3520 (0.3627)  classification: 0.0784 (0.1188)  bbox_regression: 0.2721 (0.2439)  time: 0.7433  data: 0.0048  max mem: 13498\n","Epoch: [4]  [14000/15031]  eta: 0:12:49  lr: 0.000427  loss: 0.3193 (0.3628)  classification: 0.0800 (0.1187)  bbox_regression: 0.2255 (0.2440)  time: 0.7533  data: 0.0039  max mem: 13498\n","Epoch: [4]  [15000/15031]  eta: 0:00:23  lr: 0.000427  loss: 0.3575 (0.3630)  classification: 0.1239 (0.1189)  bbox_regression: 0.2513 (0.2442)  time: 0.7439  data: 0.0047  max mem: 13498\n","Epoch: [4]  [15030/15031]  eta: 0:00:00  lr: 0.000427  loss: 0.3538 (0.3631)  classification: 0.1069 (0.1189)  bbox_regression: 0.2633 (0.2442)  time: 0.7432  data: 0.0044  max mem: 13498\n","Epoch: [4] Total time: 3:07:10 (0.7471 s / it)\n","============================================================\n","Epoch: [5]  [    0/15031]  eta: 2:57:07  lr: 0.000250  loss: 0.2871 (0.2871)  classification: 0.0758 (0.0758)  bbox_regression: 0.2113 (0.2113)  time: 0.7070  data: 0.0067  max mem: 13498\n","Epoch: [5]  [ 1000/15031]  eta: 2:54:08  lr: 0.000250  loss: 0.3142 (0.3384)  classification: 0.0993 (0.1044)  bbox_regression: 0.2041 (0.2340)  time: 0.7371  data: 0.0041  max mem: 13498\n","Epoch: [5]  [ 2000/15031]  eta: 2:41:40  lr: 0.000250  loss: 0.3023 (0.3372)  classification: 0.0863 (0.1043)  bbox_regression: 0.2418 (0.2329)  time: 0.7243  data: 0.0038  max mem: 13498\n","Epoch: [5]  [ 3000/15031]  eta: 2:29:31  lr: 0.000250  loss: 0.2844 (0.3366)  classification: 0.0778 (0.1046)  bbox_regression: 0.2006 (0.2319)  time: 0.7425  data: 0.0039  max mem: 13498\n","Epoch: [5]  [ 4000/15031]  eta: 2:17:05  lr: 0.000250  loss: 0.3343 (0.3364)  classification: 0.1034 (0.1046)  bbox_regression: 0.2212 (0.2318)  time: 0.7665  data: 0.0040  max mem: 13498\n","Epoch: [5]  [ 5000/15031]  eta: 2:04:38  lr: 0.000250  loss: 0.2874 (0.3388)  classification: 0.0903 (0.1058)  bbox_regression: 0.2068 (0.2329)  time: 0.7304  data: 0.0040  max mem: 13498\n","Epoch: [5]  [ 6000/15031]  eta: 1:52:15  lr: 0.000250  loss: 0.2557 (0.3374)  classification: 0.0736 (0.1052)  bbox_regression: 0.1810 (0.2323)  time: 0.7538  data: 0.0040  max mem: 13498\n","Epoch: [5]  [ 7000/15031]  eta: 1:39:50  lr: 0.000250  loss: 0.3372 (0.3368)  classification: 0.0731 (0.1047)  bbox_regression: 0.2688 (0.2321)  time: 0.7582  data: 0.0041  max mem: 13498\n","Epoch: [5]  [ 8000/15031]  eta: 1:27:23  lr: 0.000250  loss: 0.3415 (0.3365)  classification: 0.0724 (0.1047)  bbox_regression: 0.2642 (0.2318)  time: 0.7332  data: 0.0041  max mem: 13498\n","Epoch: [5]  [ 9000/15031]  eta: 1:14:59  lr: 0.000250  loss: 0.2795 (0.3360)  classification: 0.0947 (0.1044)  bbox_regression: 0.2090 (0.2316)  time: 0.7400  data: 0.0042  max mem: 13498\n","Epoch: [5]  [10000/15031]  eta: 1:02:31  lr: 0.000250  loss: 0.3309 (0.3359)  classification: 0.0895 (0.1039)  bbox_regression: 0.2227 (0.2320)  time: 0.7396  data: 0.0039  max mem: 13498\n","Epoch: [5]  [11000/15031]  eta: 0:50:06  lr: 0.000250  loss: 0.3473 (0.3362)  classification: 0.1031 (0.1041)  bbox_regression: 0.2453 (0.2321)  time: 0.7357  data: 0.0037  max mem: 13498\n","Epoch: [5]  [12000/15031]  eta: 0:37:41  lr: 0.000250  loss: 0.3033 (0.3367)  classification: 0.0858 (0.1043)  bbox_regression: 0.2154 (0.2324)  time: 0.7284  data: 0.0040  max mem: 13498\n","Epoch: [5]  [13000/15031]  eta: 0:25:15  lr: 0.000250  loss: 0.2836 (0.3367)  classification: 0.0698 (0.1041)  bbox_regression: 0.2064 (0.2327)  time: 0.7491  data: 0.0039  max mem: 13498\n","Epoch: [5]  [14000/15031]  eta: 0:12:49  lr: 0.000250  loss: 0.2894 (0.3373)  classification: 0.0729 (0.1043)  bbox_regression: 0.2121 (0.2329)  time: 0.7388  data: 0.0037  max mem: 13498\n","Epoch: [5]  [15000/15031]  eta: 0:00:23  lr: 0.000250  loss: 0.3553 (0.3373)  classification: 0.0758 (0.1044)  bbox_regression: 0.2541 (0.2329)  time: 0.7477  data: 0.0041  max mem: 13498\n","Epoch: [5]  [15030/15031]  eta: 0:00:00  lr: 0.000250  loss: 0.3026 (0.3373)  classification: 0.0794 (0.1043)  bbox_regression: 0.2220 (0.2329)  time: 0.7117  data: 0.0041  max mem: 13498\n","Epoch: [5] Total time: 3:06:58 (0.7463 s / it)\n","============================================================\n","Epoch: [6]  [    0/15031]  eta: 3:55:31  lr: 0.000073  loss: 0.8051 (0.8051)  classification: 0.6337 (0.6337)  bbox_regression: 0.1714 (0.1714)  time: 0.9401  data: 0.0072  max mem: 13498\n","Epoch: [6]  [ 1000/15031]  eta: 2:54:04  lr: 0.000073  loss: 0.3112 (0.3179)  classification: 0.0788 (0.0973)  bbox_regression: 0.2532 (0.2206)  time: 0.7365  data: 0.0038  max mem: 13498\n","Epoch: [6]  [ 2000/15031]  eta: 2:42:03  lr: 0.000073  loss: 0.2773 (0.3102)  classification: 0.0594 (0.0923)  bbox_regression: 0.1827 (0.2180)  time: 0.7361  data: 0.0038  max mem: 13498\n","Epoch: [6]  [ 3000/15031]  eta: 2:29:48  lr: 0.000073  loss: 0.2457 (0.3099)  classification: 0.0570 (0.0913)  bbox_regression: 0.1826 (0.2187)  time: 0.7496  data: 0.0042  max mem: 13498\n"]}]},{"cell_type":"markdown","metadata":{"id":"xXQPZzu95SF7"},"source":["## 2. fasterRCNN with backbone resnet152"],"id":"xXQPZzu95SF7"},{"cell_type":"code","metadata":{"id":"XuQbEqcHvLGb"},"source":["backbone=nn.Sequential(*list(models.resnet152(pretrained=True).children())[:-2]).to(device)\n","backbone.out_channels = 2048\n","anchor_generator = AnchorGenerator(sizes=((32, 64, 128, 256, 512),),\n","                    aspect_ratios=((0.5, 1.0, 2.0),))\n","roi_pooler = torchvision.ops.MultiScaleRoIAlign(featmap_names=['0'],\n","                            output_size=7,\n","                            sampling_ratio=2)\n","\n","model = models.detection.FasterRCNN(backbone,\n","            num_classes=10,\n","            rpn_anchor_generator=anchor_generator,\n","            box_roi_pool=roi_pooler\n","            )\n","\n","model.to(device)\n","\n","# construct an optimizer\n","params = [p for p in model.parameters() if p.requires_grad]\n","\n","# SGD\n","optimizer = torch.optim.SGD(params, \n","                lr=0.0005,\n","                momentum=0.9, \n","                weight_decay=5e-4)\n","\n","# cos warmup annealing\n","lr_scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=1, T_mult=2)\n","\n","epochs = 31\n","\n","for epoch in range(0, epochs):\n","    # train for one epoch, printing every 10 iterations\n","    train_one_epoch(model, optimizer, train_loader, device, epoch, print_freq=1000)\n","    # save model parameter\n","    torch.save(model, f'./model_para/retinanet{epoch}.pt')\n","    # update the learning rate\n","    lr_scheduler.step()\n","    # evaluate on the test dataset    \n","    evaluate(model, val_loader, device=device)  \n","    print(\"=\"*60)  \n","print('finally finished.......QQQQQQ')\n"],"id":"XuQbEqcHvLGb","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Rl0bVh9r5vGe"},"source":["## 3. try to ensemble the output of different models"],"id":"Rl0bVh9r5vGe"},{"cell_type":"code","metadata":{"id":"4b6o30Ly5t_X"},"source":["model1 = models.detection.retinanet_resnet50_fpn(pretrained=False,\n","                                                 progress=True, \n","                                                 num_classes=10,\n","                                                 pretrained_backbone=True)\n","model2 = models.detection.retinanet_resnet50_fpn(pretrained=False,\n","                                                 progress=True, \n","                                                 num_classes=10,\n","                                                 pretrained_backbone=True)\n","model1 = torch.load('./model_para/retinanet3.pt')\n","model2 = torch.load('./model_para/retinanet5-2.pt')\n","\n","model1.to(device)\n","model2.to(device)\n","\n","final_record = []\n","\n","start_time = time.time()\n","for img, img_id in tqdm(test_loader):\n","    prediction=[]\n","    model1.eval()\n","    model2.eval()\n","    with torch.no_grad():\n","        prediction1 = model1([img[0].to(device)])\n","        prediction2 = model2([img[0].to(device)])\n","        prediction = prediction1\n","\n","        prediction[0]['boxes'] = torch.cat((prediction[0]['boxes'], prediction2[0]['boxes']), 0)\n","        prediction[0]['image_id'] = torch.cat((prediction[0]['image_id'], prediction2[0]['image_id']), 0)\n","        prediction[0]['labels'] = torch.cat((prediction[0]['labels'], prediction2[0]['labels']), 0)\n","        prediction[0]['scores'] = torch.cat((prediction[0]['scores'], prediction2[0]['scores']), 0)\n","        \n","\n","    final_indice = torchvision.ops.batched_nms(boxes=prediction[0]['boxes'], \n","                                               scores=prediction[0]['scores'], \n","                                               idxs=prediction[0]['labels'], \n","                                               iou_threshold=0.5) \n","    \n","    for i in final_indice:\n","        i = i.item()\n","        box_info = {}\n","        # image_id\n","        box_info['image_id'] = img_id[0]\n","        # score\n","        box_info['score'] = prediction[0]['scores'][i].item()\n","        # category_id\n","        label = prediction[0]['labels'][i].item()\n","        box_info['category_id'] = label\n","        # bbox\n","        x1 = prediction[0]['boxes'][i][0].item()\n","        y1 = prediction[0]['boxes'][i][1].item()\n","        x2 = prediction[0]['boxes'][i][2].item()\n","        y2 = prediction[0]['boxes'][i][3].item()\n","        width = x2 - x1\n","        height = y2 - y1\n","        box_info['bbox'] = [x1, y1, width, height]\n","        final_record.append(box_info)\n","\n","end_time  = time.time()\n","print(\"\\nInference time per image: \", (end_time - start_time) / len(test_loader))\n","\n","json_obj = json.dumps(final_record, indent=4)\n","with open('answer.json', 'w') as f:\n","    f.write(json_obj)"],"id":"4b6o30Ly5t_X","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"HDqNmrcfBX_H"},"source":["## evaluate"],"id":"HDqNmrcfBX_H"},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ocFM0zoi6kQZ","executionInfo":{"status":"ok","timestamp":1637463414985,"user_tz":-480,"elapsed":1791740,"user":{"displayName":"Yi-Jing Sie","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08533209739136415786"}},"outputId":"dcd41e7b-b171-486b-8de0-d798dabe275c"},"source":["#evaluate\n","\n","model = models.detection.retinanet_resnet50_fpn(pretrained=False,\n","                                                progress=True, \n","                                                num_classes=10,\n","                                                pretrained_backbone=True)\n","\n","backbone=nn.Sequential(*list(models.resnet152(pretrained=True).children())[:-2]).to(device)\n","backbone.out_channels = 2048\n","anchor_generator = AnchorGenerator(sizes=((32, 64, 128, 256, 512),),\n","                    aspect_ratios=((0.5, 1.0, 2.0),))\n","roi_pooler = torchvision.ops.MultiScaleRoIAlign(featmap_names=['0'],\n","                            output_size=7,\n","                            sampling_ratio=2)\n","\n","model = models.detection.FasterRCNN(backbone,\n","            num_classes=10,\n","            rpn_anchor_generator=anchor_generator,\n","            box_roi_pool=roi_pooler\n","            )\n","\n","model.to(device)\n","# model = models.detection.RetinaNet(backbone,\n","#                                     num_classes=10,\n","#                                     anchor_generator=anchor_generator\n","#                                     )\n","# model = torch.load('./model_para/152_retinanet5.pt')\n","device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n","model.to(device)\n","\n","final_record = []\n","\n","start_time = time.time()\n","for img, img_id in tqdm(test_loader):\n","    model.eval()\n","    with torch.no_grad():\n","        prediction = model([img[0].to(device)])\n","\n","    for i in range(prediction[0]['boxes'].cpu().shape[0]):\n","        box_info = {}\n","        # image_id\n","        box_info['image_id'] = img_id[0]\n","        # score\n","        box_info['score'] = prediction[0]['scores'][i].item()\n","        # category_id\n","        label = prediction[0]['labels'][i].item()\n","        box_info['category_id'] = label\n","        # bbox\n","        x1 = prediction[0]['boxes'][i][0].item()\n","        y1 = prediction[0]['boxes'][i][1].item()\n","        x2 = prediction[0]['boxes'][i][2].item()\n","        y2 = prediction[0]['boxes'][i][3].item()\n","        width = x2 - x1\n","        height = y2 - y1\n","        box_info['bbox'] = [x1, y1, width, height]\n","        final_record.append(box_info)\n","\n","end_time  = time.time()\n","print(\"\\nInference time per image: \", (end_time - start_time) / len(test_loader))\n","\n","json_obj = json.dumps(final_record, indent=4)\n","with open('answer.json', 'w') as f:\n","    f.write(json_obj)"],"id":"ocFM0zoi6kQZ","execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13068/13068 [29:49<00:00,  7.30it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","Inference time per image:  17.893013916015626\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}]},{"cell_type":"code","metadata":{"id":"V-CFtIQ5GiBS"},"source":["\n","    "],"id":"V-CFtIQ5GiBS","execution_count":null,"outputs":[]}]}